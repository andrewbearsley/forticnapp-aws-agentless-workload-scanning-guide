---
alwaysApply: true
description: Guidelines for investigation-based workspaces focused on answering customer questions, extracting data, or researching information rather than building software.
---

# Investigation Workspace Guidelines

Investigation workspaces are different from development projects. They focus on answering questions, extracting data, researching information, or analyzing existing systems rather than building new software.

## Characteristics of Investigation Workspaces

- **Goal**: Answer a specific question or extract specific information
- **Output**: Reports, data exports, summaries, documentation, customer communications
- **Approach**: Often exploratory with multiple methods attempted
- **Structure**: More flexible, may include multiple approaches in parallel
- **Timeline**: Usually shorter-term, focused on delivering answers

## Workspace Structure

Investigation workspaces typically include:

```
.
├── SUMMARY.md              # What question are we answering? Why?
├── README.md               # How to run scripts, what each approach does
├── reference/              # Reference data (from APIs, CLI, source systems)
│   └── *.json, *.csv
├── approach-1/             # First investigation approach
│   ├── README.md
│   ├── input/             # Source data for this approach
│   ├── scripts/           # Extraction/analysis scripts
│   └── results/           # Outputs from this approach
├── approach-2/            # Alternative approach (if needed)
│   └── ...
├── customer-comms/         # Customer-facing communications
│   └── *.txt, *.md
└── scripts/                # Shared/common scripts
    └── *.py, *.sh
```

## Key Differences from Development Projects

### Documentation Focus
- **SUMMARY.md**: Focus on the question/problem, not the solution architecture
- **README.md**: Focus on how to use the tools, not how the system works
- **LEARNINGS.md**: Document what was discovered, what worked, what didn't
- **Customer communications**: Clear, concise answers to the original question

### Multiple Approaches
- It's common to try multiple methods (e.g., PDF extraction vs. web scraping)
- Each approach should be self-contained with its own folder
- Document which approach worked best and why
- Keep all approaches for reference, even if one is preferred

### Data Flow
- **Input**: Source data (PDFs, web pages, API responses, CLI output)
- **Reference**: Extracted reference data (policies, mappings, etc.)
- **Results**: Processed outputs (CSV, JSON, reports)
- **Customer-comms**: Final deliverables for the customer

### Scripts
- Scripts are tools for extraction/analysis, not production code
- Focus on correctness and clarity over performance
- Include error handling and helpful error messages
- Document assumptions and limitations

## Investigation Process

1. **Understand the Question**
   - What exactly is the customer asking?
   - What format do they need the answer in?
   - What constraints exist (time, data sources, etc.)?

2. **Explore Approaches**
   - Identify possible data sources
   - Try multiple extraction methods if needed
   - Document what works and what doesn't

3. **Extract and Process**
   - Extract raw data from sources
   - Process and merge with reference data
   - Validate results

4. **Document Findings**
   - Create LEARNINGS.md with discoveries
   - Document which approach worked best
   - Note any gotchas or limitations

5. **Deliver Answer**
   - Format output for customer needs
   - Create customer communication
   - Include relevant documentation links

## Best Practices

### Start with the Question
- Write SUMMARY.md first - clearly state what you're investigating
- Keep the question visible throughout the investigation

### Try Multiple Approaches
- Don't commit to one method too early
- Keep approaches separate and documented
- Compare results to validate

### Document Everything
- What sources were used
- What worked and what didn't
- What assumptions were made
- What limitations exist

### Keep It Simple
- Use straightforward scripts over complex architectures
- Prefer readable code over optimized code
- Focus on getting the answer, not building a system

### Customer-Focused Output
- Format results for customer needs (CSV, email, report)
- Include context and documentation links
- Make it easy for them to use the information

## Common Patterns

### Data Extraction
- Extract from multiple sources (PDFs, web, APIs, CLI)
- **Try API endpoints first** - Check if data is available via API before using PDF/web scraping
- Merge with reference data
- Validate completeness and accuracy

### API-First Approach
When investigating Lacework data:
1. Check if data is available via API first
2. **Test API endpoints** - Don't assume they work; verify with actual calls
3. If API doesn't work, fall back to PDF extraction or web scraping
4. Document API test results (what worked, what didn't, error messages)
5. API data is usually more structured and reliable when available

**Note:** The `api/v2/Reports` endpoint for compliance reports does not work for policy inventory extraction (returns null). Use PDF or web scraping approaches instead.

### Multiple Formats
- Generate multiple output formats (JSON, CSV, TXT)
- JSON for processing, CSV for analysis, TXT for email

### Reference Data
- Extract common reference data once (e.g., all policies from CLI)
- Reuse across multiple approaches
- Keep in `reference/` folder

### Customer Communication
- Create `customer-comms/` folder for deliverables
- Include clear subject lines and context
- Attach relevant files and documentation links

## When to Use This Structure

Use investigation workspace structure when:
- Answering a specific customer question
- Extracting data from existing systems
- Researching and documenting information
- Comparing different data sources or methods
- Creating reports or summaries
- Analyzing existing data

Don't use this structure when:
- Building production software
- Creating reusable libraries or tools
- Developing long-term systems
- Working on infrastructure code

## Example Investigation Questions

- "What policies are in the CIS AWS 4.0.1 framework?"
- "How do two compliance frameworks compare?"
- "What data can we extract from this API?"
- "What's the difference between these two systems?"
- "Can we generate a report from this data source?"
